{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loads input volumetric data and convert in 2D images training format\n",
    "* input image -> WH\n",
    "* output image -> WH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/hasib/MRI-reconstruction/dataset/singlecoil_train_3D_images_48x_normalized/low/',\n",
       " '/home/hasib/MRI-reconstruction/dataset/singlecoil_train_3D_images_48x_normalized/high/')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import helpers as H\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\".\")\n",
    "TRAIN_DATASET_PATH = os.path.join(ROOT_DIR, \"dataset\")\n",
    "\n",
    "# Dataset directories\n",
    "LOW_DIR = \"singlecoil_train_3D_images_48x_normalized/low/\"\n",
    "HIGH_DIR = \"singlecoil_train_3D_images_48x_normalized/high/\"\n",
    "\n",
    "LOW_DIR_PATH = os.path.join(TRAIN_DATASET_PATH, LOW_DIR)\n",
    "HIGH_DIR_PATH = os.path.join(TRAIN_DATASET_PATH, HIGH_DIR)\n",
    "#SAVE_DATA_PATH = os.path.join(TRAIN_DATASET_PATH, \"singlecoil_train_3D_images_48x_normalized\")\n",
    "LOW_DIR_PATH, HIGH_DIR_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = 128, 128\n",
    "def rs_img(img):\n",
    "    '''W and H is 128 now\n",
    "    '''\n",
    "    print(img.shape[-1])\n",
    "    print(type(img.shape[-1]))\n",
    "    flatten = [cv2.resize(img[:,:,i], (w, h), interpolation=cv2.INTER_CUBIC) for i in range(img.shape[-1])]\n",
    "    img = np.array(np.dstack(flatten)) \n",
    "    return img\n",
    "\n",
    "\n",
    "def change_depth(img):\n",
    "\n",
    "    img_start = img[:,:,:4]\n",
    "    \n",
    "    mid = int(img.shape[-1]/2)\n",
    "    img_middle = img[:,:,mid-10:mid+10]\n",
    "    \n",
    "    img_end = img[:,:,-4:]\n",
    "    img = np.concatenate((img_start, img_middle, img_end), axis=2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def show_slices(data, slice_nums, cmap=None):\n",
    "    data = np.moveaxis(data, 2, 0)\n",
    "    fig = plt.figure(figsize=(16, 16))\n",
    "    for i, num in enumerate(slice_nums):\n",
    "        plt.subplot(1, len(slice_nums), i + 1)\n",
    "        plt.imshow(data[num], cmap=cmap)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check number of contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(LOW_DIR_PATH)), len(os.listdir(HIGH_DIR_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_full_paths = [\"{}/{}\".format(LOW_DIR_PATH,l) for l in H.sort_paths(os.listdir(LOW_DIR_PATH))]\n",
    "high_full_paths = [\"{}/{}\".format(HIGH_DIR_PATH,h) for h in H.sort_paths(os.listdir(HIGH_DIR_PATH))]\n",
    "\n",
    "len(low_full_paths), len(high_full_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/hasib/MRI-reconstruction/dataset/singlecoil_train_3D_images_48x_normalized/low//1.npy',\n",
       " '/home/hasib/MRI-reconstruction/dataset/singlecoil_train_3D_images_48x_normalized/low//2.npy',\n",
       " '/home/hasib/MRI-reconstruction/dataset/singlecoil_train_3D_images_48x_normalized/low//3.npy',\n",
       " '/home/hasib/MRI-reconstruction/dataset/singlecoil_train_3D_images_48x_normalized/low//4.npy']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_full_paths[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/hasib/MRI-reconstruction/dataset/singlecoil_train_3D_images_48x_normalized/high//1.npy',\n",
       " '/home/hasib/MRI-reconstruction/dataset/singlecoil_train_3D_images_48x_normalized/high//2.npy',\n",
       " '/home/hasib/MRI-reconstruction/dataset/singlecoil_train_3D_images_48x_normalized/high//3.npy',\n",
       " '/home/hasib/MRI-reconstruction/dataset/singlecoil_train_3D_images_48x_normalized/high//4.npy']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_full_paths[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make folder for low and high res\n",
    "\n",
    "LOW_DIR_2D = \"singlecoil_train_2D_images_normalized/low/\"\n",
    "HIGH_DIR_2D = \"singlecoil_train_2D_images_normalized/high/\"\n",
    "\n",
    "H.create_directory(\"{}/{}\".format(TRAIN_DATASET_PATH, LOW_DIR_2D))\n",
    "H.create_directory(\"{}/{}\".format(TRAIN_DATASET_PATH, HIGH_DIR_2D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/hasib/MRI-reconstruction/dataset/singlecoil_train_2D_images_normalized/low/',\n",
       " '/home/hasib/MRI-reconstruction/dataset/singlecoil_train_2D_images_normalized/high/')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOW_DIR_2D_PATH = os.path.join(TRAIN_DATASET_PATH, LOW_DIR_2D)\n",
    "HIGH_DIR_2D_PATH = os.path.join(TRAIN_DATASET_PATH, HIGH_DIR_2D)\n",
    "LOW_DIR_2D_PATH, HIGH_DIR_2D_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before saving \n",
    "# img_3d_gt[20] raw data\n",
    "#img = img_3d_gt[20].astype('float64') * 255.0\n",
    "#cv2.imwrite(\"test.png\", img)\n",
    "\n",
    "# reading\n",
    "#b = cv2.imread(\"test.png\", cv2.IMREAD_UNCHANGED)\n",
    "#b = b.astype('float64') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low MRI 3D to 2D image slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total slices: 293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "total_slices = 0\n",
    "\n",
    "for l in tqdm(low_full_paths[:]):\n",
    "    img_3d = np.load(\"{}\".format(l))\n",
    "    img_3d = np.moveaxis(img_3d, 0, 2)\n",
    "    slices = img_3d.shape[-1]\n",
    "    total_slices+=slices\n",
    "    \n",
    "    # iterate over each slice and save\n",
    "    for i in range(slices):\n",
    "        img = img_3d[:,:,i]\n",
    "        \n",
    "        img = img.astype('float64') * 255.0\n",
    "        cv2.imwrite(\"{}/{}_{}.jpg\".format(LOW_DIR_2D_PATH, c, i), img)\n",
    "        \n",
    "        #plt.imsave(\"{}/{}_{}.jpg\".format(LOW_DIR_2D_PATH, c, i), img, cmap='gray')\n",
    "        img = None\n",
    "        \n",
    "    img_3d = None\n",
    "    c+=1\n",
    "    \n",
    "print(\"Total slices: {}\".format(total_slices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HIGH MRI VOLUMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total slices: 293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "total_slices = 0\n",
    "\n",
    "for l in tqdm(high_full_paths[:]):\n",
    "    img_3d = np.load(\"{}\".format(l))\n",
    "    img_3d = np.moveaxis(img_3d, 0, 2)\n",
    "    slices = img_3d.shape[-1]\n",
    "    total_slices+=slices\n",
    "    \n",
    "    # iterate over each slice and save\n",
    "    for i in range(slices):\n",
    "        img = img_3d[:,:,i]\n",
    "        #print(img[10:12, 20:24])\n",
    "        \n",
    "        img = img.astype('float64') * 255.0\n",
    "        cv2.imwrite(\"{}/{}_{}.jpg\".format(HIGH_DIR_2D_PATH, c, i), img)\n",
    "        \n",
    "        #plt.imsave(\"{}/{}_{}.jpg\".format(HIGH_DIR_2D_PATH, c, i), img, cmap='gray')\n",
    "        img = None\n",
    "        \n",
    "    img_3d = None\n",
    "    c+=1\n",
    "    \n",
    "print(\"Total slices: {}\".format(total_slices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default image is loaded as RGB even though it is grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### During test time:\n",
    "* load from *.h5 files and convert and save to npy\n",
    "* for each npy file\n",
    "    make folder of npy file name\n",
    "    convert each slice and save in folder\n",
    "* Now we have X number of test volume folders which have all slices\n",
    "* Run 2D model on each folder(npy file) and reconstruct output volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
